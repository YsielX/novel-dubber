Metadata-Version: 2.4
Name: novel-dubber
Version: 0.1.0
Summary: CLI tool to dub audiobooks using ASR, diarization, LLM, and GPT-SoVITS
Author: Codex
License: MIT
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Requires-Python: >=3.9
Description-Content-Type: text/markdown
Requires-Dist: typer>=0.12.3
Requires-Dist: rich>=13.7.1
Requires-Dist: tqdm>=4.66.4
Requires-Dist: pyyaml>=6.0.1
Requires-Dist: requests>=2.32.3
Requires-Dist: openai>=1.40.0

# novel-dubber

Production-grade CLI to dub audiobooks using local ASR + diarization, an external OpenAI-compatible LLM for labeling/translation, and GPT-SoVITS for synthesis.

## Install

```bash
pip install -e .
```

## Quickstart

### Audio-only (MODE A)

```bash
novel_dubber run-audio --audio audiobook.mp3 --workdir workdir --target-lang en
```

Or step-by-step:

```bash
novel_dubber audio-analyze --audio audiobook.mp3 --out workdir
novel_dubber audio-discover-characters --workdir workdir --out workdir
# (optional) edit workdir/characters.json to merge aliases
novel_dubber audio-dump-voices --workdir workdir --out workdir
novel_dubber audio-dub --workdir workdir --target-lang en --out outdir
```

### Text + manual voice map (MODE B)

```bash
novel_dubber text-dub --text novel.txt --voice-map voice_map.json --target-lang en --out outdir
```

Voice map schema:

```json
{
  "NARRATOR": {"ref_audio": "path/to.wav", "ref_text": "reference transcript"},
  "CharacterA": {"ref_audio": "path/to.wav", "ref_text": "reference transcript"}
}
```

## Workdir layout (cache/resume)

- `chunks/` audio chunks + `manifest.json`
- `diarization.json` combined diarization
- `asr_segments.jsonl` raw ASR
- `segments.jsonl` merged ASR + diarization
- `labeled_segments.jsonl` role/character labeling
- `voice_map.json` + `voice_map/<character>/ref_###.wav`
- `translated_segments.jsonl`
- `tts_segments/seg_####.wav`
- `final_audio.wav` + `final_audio.mp3`

## Config

Edit `config.yaml` or pass `--config path/to.yaml`.

Key settings:
- `llm.endpoint`, `llm.model`, `llm.api_key_env`
- `asr.command_template`, `diarization.command_template`
- `tts.mode` (`http` or `cli`) and adapter config
- `character_discovery.window_size`, `labeling.character_list_path`

The LLM API key is read from the environment variable specified in `llm.api_key_env`.

## Full pipeline commands

Audio-only (recommended step order):

```bash
# 1) preprocess + ASR (and diarization if enabled)
novel_dubber audio-analyze --audio audiobook.mp3 --out workdir --language ja

# 2) discover character list (no overlap windows)
novel_dubber audio-discover-characters --workdir workdir --out workdir

# 3) edit character aliases if needed
cat workdir/characters.json

# 4) label + extract voice refs
novel_dubber audio-dump-voices --workdir workdir --out workdir

# 5) translate + TTS + stitch
novel_dubber audio-dub --workdir workdir --target-lang en --out outdir
```

Text mode:

```bash
novel_dubber text-dub --text novel.txt --voice-map voice_map.json --target-lang en --out outdir
```

## External tool expectations

### ASR
The ASR command must output JSONL at the given `{out}` path. Each line:

```json
{"start": 12.34, "end": 15.67, "text": "...", "confidence": 0.91}
```

Times must be in seconds relative to the input chunk audio.

### Diarization
The diarization command must output JSON at `{out}`. Format:

```json
[
  {"start": 10.0, "end": 14.2, "speaker": "SPEAKER_00", "overlap": false},
  {"start": 14.2, "end": 17.0, "speaker": "SPEAKER_01", "overlap": true}
]
```

Times must be in seconds relative to the input chunk audio.

### GPT-SoVITS
- **HTTP mode** expects a WAV response or JSON containing `audio_path` or `audio_base64`.
- **CLI mode** uses `tts.cli.command_template` with placeholders `{text_file}`, `{ref_audio}`, `{ref_text}`, `{out}`, `{target_lang}`.

## Troubleshooting

- **ffmpeg not found**: ensure `ffmpeg` is on PATH for both Windows and Linux.
- **Large files**: use a large chunk size (e.g. 1800s). Resume is automatic if outputs exist.
- **GPU optional**: set `asr.device=cpu` if no GPU.
- **LLM errors**: verify endpoint/model and API key env var.

## Smoke tests

```bash
pytest -q
```
